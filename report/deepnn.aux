\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{Part 1}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces 100 randomly picked $28\times 28$ images in gray scale, 10 images for each number. The first eight columns are images from training sets, the last two columns are images from the validation sets. The handwritten numbers in the images are all recognizable.\relax }}{3}}
\@writefile{toc}{\contentsline {section}{Part 2}{4}}
\@writefile{toc}{\contentsline {section}{Part 3}{4}}
\@writefile{toc}{\contentsline {section}{Part 4}{6}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sfig1}{{2a}{6}}
\newlabel{sub@fig:sfig1}{{a}{6}}
\newlabel{fig:sfig2}{{2b}{6}}
\newlabel{sub@fig:sfig2}{{b}{6}}
\newlabel{fig:sfig3}{{2c}{6}}
\newlabel{sub@fig:sfig3}{{c}{6}}
\newlabel{fig:sfig4}{{2d}{6}}
\newlabel{sub@fig:sfig4}{{d}{6}}
\newlabel{fig:sfig5}{{2e}{6}}
\newlabel{sub@fig:sfig5}{{e}{6}}
\newlabel{fig:sfig6}{{2f}{6}}
\newlabel{sub@fig:sfig6}{{f}{6}}
\newlabel{fig:sfig4}{{2g}{6}}
\newlabel{sub@fig:sfig4}{{g}{6}}
\newlabel{fig:sfig5}{{2h}{6}}
\newlabel{sub@fig:sfig5}{{h}{6}}
\newlabel{fig:sfig6}{{2i}{6}}
\newlabel{sub@fig:sfig6}{{i}{6}}
\newlabel{fig:sfig6}{{2j}{6}}
\newlabel{sub@fig:sfig6}{{j}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \relax }}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Learning curve: red line represents for the performance on the taining set. Green dotted line represents the performance on the testing set.\relax }}{7}}
\@writefile{toc}{\contentsline {section}{Part 5}{7}}
\@writefile{toc}{\contentsline {section}{Part 6}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Professor reply\relax }}{13}}
\@writefile{toc}{\contentsline {section}{Part 7}{14}}
\newlabel{fig:sfig3}{{\caption@xref {fig:sfig3}{ on input line 707}}{14}}
\newlabel{sub@fig:sfig3}{{}{14}}
\newlabel{fig:sfig3}{{\caption@xref {fig:sfig3}{ on input line 714}}{14}}
\newlabel{sub@fig:sfig3}{{a}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Image with incorrect bounding box\relax }}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Image shows only one side of the face\relax }}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Images show only one side of the face\relax }}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The performance on the training set come very closed to 100\% after 500 iterations of gradient descent. The correctness rates on the validation and testing set are peaked at 87\%, this is the highest value that I could get after trying to vary the number of hidden units as well as using different activation functions. Any number of hidden units greater than 30 would not give better performance on the validation and testing set than this configuration.\relax }}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces After 500 iterations, a neural network with only 5 hidden units only gave the correct rates no better than 50 \%. This is to illustrate that the number of hidden units in a network could influence the performance. In this case, the low number of hidden units caused underfitting.\relax }}{16}}
\@writefile{toc}{\contentsline {section}{Part 8}{17}}
\@writefile{toc}{\contentsline {section}{Part 9}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces To make the images look smoother, I also used weight decay with $\lambda =10$.\relax }}{20}}
\@writefile{toc}{\contentsline {section}{Part 10}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces After just 50 iterations, the correctness rates on the training, validation and testing sets are all greater than 95\%. \relax }}{21}}
\newlabel{LastPage}{{}{21}}
\xdef\lastpage@lastpage{21}
\gdef\lastpage@lastpageHy{}
